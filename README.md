# Jacmate ‚Äî RAG Research Assistant üîéü§ñ

**Short description:** Jacmate is a Retrieval-Augmented Generation (RAG) system that ingests local research PDFs and text files into a persistent ChromaDB vector store, uses LangChain tooling for loading, chunking and embedding, and calls OpenAI chat models (via LangChain) to produce human-readable answers to research questions.

---

## Table of contents
- [Quick start](#quick-start)
- [Prerequisites](#prerequisites)
- [Install & setup](#install--setup)
- [Data ingestion](#data-ingestion)
- [Retrieval & API usage](#retrieval--api-usage)
- [Switching models](#switching-models)
- [Files & structure](#files--structure)
- [Reproducible artifacts](#reproducible-artifacts)
- [Security & best practices](#security--best-practices)
- [Contributing & license](#contributing--license)

---

## Quick start ‚úÖ
1. Create and activate a virtual environment:

```bash
python -m venv .venv
source .venv/bin/activate
```

2. Install dependencies:

```bash
pip install -r requirements.txt
```

3. Set your OpenAI key in a `.env` file (create `.env` in the repo root):

```
OPENAI_API_KEY=sk-...
```

4. Ingest your research files into ChromaDB:

```bash
python insert_chroma.py
```

5. Run the API server:

```bash
python app.py
# or
uvicorn app:app --host 0.0.0.0 --port 8000
```

6. Query the API (example):

```bash
curl -X POST "http://localhost:8000/ask" -H "Content-Type: application/json" -d '{"question": "Summarize the main contributions in the ML papers."}'
```

---

## Prerequisites
- Python 3.10+ (a virtual environment is recommended)
- An OpenAI API key (set in `.env`)
- Optional: GPU drivers if you intend to use CUDA for embeddings

---

## Install & setup
- Create a virtual environment and install packages listed in `requirements.txt`.
- The project uses LangChain community loaders (`PyPDFLoader`, `TextLoader`), HuggingFace sentence-transformers (`all-MiniLM-L6-v2`) for embeddings, and ChromaDB for vector storage.

---

## Data ingestion
- `inserting_file.py` discovers and loads files from a specified folder (it walks subfolders for PDFs and loads `.txt` files). By default `insert_chroma.py` calls:

```py
publication = load_pdf_to_strings("data/400 Level/1st Semester")
db = insert_publications(collection, publication, title="400 level")
```

- `jac_functions.chunk_research_paper` splits documents into ~1000-character chunks with 200-character overlap to preserve context.
- `jac_functions.embed_documents` uses a Hugging Face embedding model and auto-selects `cuda`, `mps`, or `cpu`.
- The persistent Chroma DB root is `./research_db` and the collection name is `ml_publications`.

Tip: to ingest a different directory, modify the path passed to `load_pdf_to_strings()` or adapt `insert_chroma.py`.

---

## Retrieval & API usage
- The FastAPI server (`app.py`) exposes `POST /ask` which accepts JSON: `{ "question": "..." }` and returns a JSON object with `answer` and `sources`.

Example Python client:

```py
import requests
payload = {'question':'Summarize the contributions across these papers.'}
resp = requests.post('http://localhost:8000/ask', json=payload)
print(resp.json())
```

How it works (short):
1. The question is embedded using the same embedding model.
2. Chroma is queried for most similar chunks (top-k).
3. A prompt is assembled (retrieved chunks + question) via `PromptTemplate`.
4. The LLM (via `ChatOpenAI`) generates the human-readable answer.

---

## Switching models
- By default, the `app.py` examples use `ChatOpenAI(model_name='gpt-4o-mini')` (commented examples). To use **GPT-3.5**, set:

```py
from langchain_openai import ChatOpenAI
llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.7)
```

Notes:
- GPT-3.5 tends to be cheaper and faster than GPT-4 models. Consider prompt length (cost) and latency when designing queries.
- You can shorten retrieved context or summarize chunks before sending to the LLM to reduce prompt size.

---

## Files & structure
- `app.py` ‚Äî FastAPI server and `/ask` endpoint
- `inserting_file.py` ‚Äî loaders for PDFs and `.txt` files
- `jac_functions.py` ‚Äî chunking, embedding, insertion, retrieval, and prompt construction
- `insert_chroma.py` ‚Äî example ingestion script
- `scripts/generate_publication.py` ‚Äî generates `publication.docx`
- `docs/diagram.svg` / `docs/diagram.png` ‚Äî architecture diagrams
- `research_db/` ‚Äî persistent ChromaDB files (not tracked by default)

---

## Reproducible artifacts
- `publication.docx` ‚Äî short project publication generated by `scripts/generate_publication.py`.
- To regenerate:

```bash
python scripts/generate_publication.py
```

- To convert to a simple PDF (basic text-only rendering) run:

```bash
python scripts/docx_to_pdf.py
```

---

## Security & best practices ‚ö†Ô∏è
- **Never commit** your `.env` or secret keys. The repo `.gitignore` should include `.env` and `research_db/`.
- For public repos, avoid committing research data or large binaries. Keep sensitive data in a private storage bucket or a private repo.

Suggested `.gitignore` entries (if you don't already have them):

```
.env
.venv
research_db/
publication.docx
publication.pdf
.DS_Store
```

---

## Contributing & license
Contributions are welcome ‚Äî please open an issue or a PR. Consider adding:
- Unit tests for `jac_functions` (chunking, embedding, retrieval).
- A small UI for exploration of retrieved context and model outputs.

License: add a `LICENSE` (recommended: MIT) if you want this repo to be shared publicly.

---

## Pushing to GitHub
If you want me to push the repo and create a GitHub repository for you I can do that (via GitHub CLI). Example commands to run locally:

```bash
git add .
git commit -m "Initial commit"
# create remote and push
gh repo create jacmate-rag --public --source=. --remote=origin --push
```

Or manually: create repo on github.com and follow their push instructions.

---

## Contact
Author: **Ugochukwu Febechukwu**

---

If you'd like, I can also:
- Create a `README` badge and `LICENSE` file for you. ‚úÖ
- Create and push the GitHub repo now (public or private). ‚ö°

What would you like me to do next? (create LICENSE / push repo / update .gitignore / other)